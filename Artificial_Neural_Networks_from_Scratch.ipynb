{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Artificial-Neural-Networks-from-Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "I7kGy9IxRlIl"
      ],
      "authorship_tag": "ABX9TyMPHwAzW4hjemRKZT+ehkFq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-asefy/neural-networks-from-zero/blob/main/Artificial_Neural_Networks_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7kGy9IxRlIl"
      },
      "source": [
        "# Neural Network Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K47Tsf-RzFI"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "\n",
        "    # راه اندازی شبکه عصبی \n",
        "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
        "        # تعیین تعداد نورون‌های لایه‌های مختلف\n",
        "        self.input_nodes = input_nodes\n",
        "        self.hidden_nodes = hidden_nodes\n",
        "        self.output_nodes = output_nodes\n",
        "\n",
        "        # تعیین نرخ یادگیری\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        # ایجاد تابع فعال سازی که اینجا سیگموییدی است ولی می تواند متفاوت باشد\n",
        "        self.activation_function = lambda x : expit(x)\n",
        "\n",
        "        # ایجاد دو ماتریس وزن‌های اولیه\n",
        "        # یکی برای وزن‌های بین لایه ورودی و مخفی و یکی برای وزن‌های بین لایه مخفی و خروجی \n",
        "        # هر وزن با ایندکس آی و جی، وزن اتصال بین نورون آی از لایه مبدا به نورون جی در لایه مقصد است.\n",
        "        #  و به همین ترتیب w12 w21 مثلا\n",
        "        self.w_i_h = np.random.default_rng().normal(0, pow(self.input_nodes, -0.5),\n",
        "                                                    (self.hidden_nodes, self.input_nodes))\n",
        "        self.w_h_o = np.random.default_rng().normal(0, pow(self.hidden_nodes, -0.5),\n",
        "                                                    (self.output_nodes, self.hidden_nodes))\n",
        "        pass\n",
        "\n",
        "\n",
        "    # محاسبه خروجی شبکه با دادن ورودی - پیش خور\n",
        "    def query(self, input_list):\n",
        "        # تبدیل لیست مقادیر ورودی به آرایه دوبعدی\n",
        "        inputs = np.array(input_list, ndmin=2).T\n",
        "\n",
        "        # محاسبه سیگنال ورودی و سپس خروجی لایه مخفی\n",
        "        x_hidden = np.dot(self.w_i_h, inputs)\n",
        "        o_hidden = self.activation_function(x_hidden)\n",
        "\n",
        "        # محاسبه سیگنال ورودی و سپس خروجی لایه خروجی\n",
        "        x_output = np.dot(self.w_h_o, o_hidden)\n",
        "        o_output = self.activation_function(x_output)\n",
        "\n",
        "        return o_output\n",
        "\n",
        "\n",
        "    # یادگیری شبکه بر اساس یک نمونه ورودی/خروجی - پس انتشار\n",
        "    def train(self, input_list, targets_list):\n",
        "        # محاسبه سیگنال‌های ورودی و خروجی لایه‌ها\n",
        "        inputs = np.array(input_list, ndmin=2).T\n",
        "\n",
        "        x_hidden = np.dot(self.w_i_h, inputs)\n",
        "        o_hidden = self.activation_function(x_hidden)\n",
        "\n",
        "        x_output = np.dot(self.w_h_o, o_hidden)\n",
        "        o_output = self.activation_function(x_output)\n",
        "\n",
        "        #محاسبه خطای شبکه بر اساس اختلاف خروجی با هدف‌ها\n",
        "        targets = np.array(targets_list, ndmin=2).T\n",
        "        output_errors = targets - o_output\n",
        "        #پس انتشار خطای شبکه روی نورون‌های لایه مخفی\n",
        "        hidden_errors = np.dot(self.w_h_o.T, output_errors)\n",
        "\n",
        "        # محاسبه وزن‌های جدید اتصال‌ها با گرادیان کاهشی\n",
        "        self.w_h_o += self.learning_rate * np.dot((output_errors * o_output * (1-o_output)), o_hidden.T)\n",
        "        self.w_i_h += self.learning_rate * np.dot((hidden_errors * o_hidden * (1-o_hidden)), inputs.T)\n",
        "        \n",
        "        \n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUm3xWxwwAMP"
      },
      "source": [
        "# Neural Network Instance Creation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# فراخوانی داده‌های آموزش از دیتاست امنیست\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_file= open('/content/drive/MyDrive/mnist/mnist_train_100.csv', 'r')\n",
        "train_list = train_file.readlines()\n",
        "train_file.close()"
      ],
      "metadata": {
        "id": "JgqwjWgBppRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nezWXnH1wEAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ef4bbb-ac89-471a-e0f0-120e122ae679"
      },
      "source": [
        "# تعیین تعداد نورون‌ها در هر لایه\n",
        "input_nodes = 784\n",
        "hidden_nodes = 100\n",
        "output_nodes = 10\n",
        "\n",
        "# تعیین نرخ یادگیری شبکه\n",
        "learning_rate = 0.3 \n",
        "\n",
        "# ساخت نمونه از شبکه عصبی با معماری بالا\n",
        "nn = NeuralNetwork(input_nodes=input_nodes,\n",
        "                   hidden_nodes=hidden_nodes, output_nodes= output_nodes, \n",
        "                   learning_rate=learning_rate)\n",
        "print(\"initial weights (W_input_hidden): \", nn.w_i_h)\n",
        "\n",
        "# آموزش شبکه ساخته شده با داده‌های آموزشی امنیست \n",
        "for row in train_list: \n",
        "   row_data = row.split(',') \n",
        "   inputs = (np.asfarray(row_data[1:]) / (255.0 * 0.99)) + 0.01\n",
        "   targets = np.zeros(n_output) + 0.01\n",
        "   targets[int(row_data[0])] = 0.99\n",
        "   nn.train(inputs, targets)\n",
        "\n",
        "print(\"\\n\\nweights (W_input_hidden) after a round of training: \", nn.w_i_h)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial weights (W_input_hidden):  [[ 0.03132964  0.04891608 -0.03069815 ... -0.00465847  0.0547763\n",
            "   0.01288061]\n",
            " [ 0.03343309 -0.01079733 -0.07629049 ... -0.01859951  0.00944889\n",
            "  -0.00803494]\n",
            " [ 0.00047567  0.04153871  0.00936476 ... -0.04767674 -0.03677919\n",
            "   0.01994046]\n",
            " ...\n",
            " [-0.02442113 -0.01964539 -0.04093524 ...  0.01351961  0.0201826\n",
            "  -0.02406652]\n",
            " [-0.03983769 -0.03483108  0.04256397 ...  0.02118299 -0.02590286\n",
            "   0.08037493]\n",
            " [-0.00246163  0.00785145 -0.04035599 ... -0.0115416   0.05762173\n",
            "   0.00405595]]\n",
            "\n",
            "\n",
            "weights (W_input_hidden) after a round of training:  [[ 0.03147152  0.04905795 -0.03055627 ... -0.00451659  0.05491817\n",
            "   0.01302249]\n",
            " [ 0.03366472 -0.0105657  -0.07605886 ... -0.01836788  0.00968052\n",
            "  -0.00780331]\n",
            " [ 0.00034441  0.04140744  0.0092335  ... -0.047808   -0.03691045\n",
            "   0.01980919]\n",
            " ...\n",
            " [-0.02499615 -0.02022041 -0.04151026 ...  0.01294459  0.01960758\n",
            "  -0.02464154]\n",
            " [-0.03922005 -0.03421344  0.04318161 ...  0.02180063 -0.02528523\n",
            "   0.08099256]\n",
            " [-0.00271789  0.00759519 -0.04061225 ... -0.01179785  0.05736547\n",
            "   0.00379969]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تمرین اتصال درایو به کولب و خواندن دیتاست امنیست\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "train_file= open('/content/drive/MyDrive/mnist/mnist_train_100.csv', 'r')\n",
        "train_list = train_file.readlines()\n",
        "train_file.close()\n",
        "train_list[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "6EGDF6aaylqQ",
        "outputId": "876e6fab-5db7-46b8-b511-2d822b1de38e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تمرین دیتاست امنیست \n",
        "\n",
        "row_data = train_list[0].split(',')\n",
        "image_data = np.asarray(row_data[1:], dtype=np.float32).reshape((28,28))\n",
        "image = plt.imshow(image_data, cmap='Greys')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "OlBvaNCJSlXM",
        "outputId": "6b689500-72d3-4f75-93c0-90aaea8c47e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تمرین مقیاس کردن داده های ورودی به محدوده ۰.۰۱ تا ۱\n",
        "scaled_input = (np.asfarray(row_data[1:]) / (255.0 * 0.99)) + 0.01\n",
        "print('scaled input for this image is: ', scaled_input)\n",
        "\n",
        "# تمرین مقیاس کردن داده های خروجی به محدوده ۰.۰۱ تا ۰.۹۹\n",
        "n_output = 10\n",
        "scaled_target = np.zeros(n_output) + 0.01\n",
        "scaled_target[int(row_data[0])] = 0.99\n",
        "print('\\nscaled target for this image is: ', scaled_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SzxszUjpQY4",
        "outputId": "0b9aabd8-eaa8-4249-df6a-b4d7f7a1d6b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scaled input for this image is:  [0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.02188354 0.08130125 0.08130125 0.08130125\n",
            " 0.50910873 0.54872054 0.70320658 0.11299069 0.66755595 1.02010101\n",
            " 0.98841157 0.51306991 0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.12883541 0.1526025  0.38235096 0.62002179\n",
            " 0.68340067 1.01217865 1.01217865 1.01217865 1.01217865 1.01217865\n",
            " 0.9012656  0.69132303 1.01217865 0.96860566 0.78243018 0.26351555\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.20409784\n",
            " 0.95276094 1.01217865 1.01217865 1.01217865 1.01217865 1.01217865\n",
            " 1.01217865 1.01217865 1.01217865 1.00425629 0.37838978 0.3348168\n",
            " 0.3348168  0.2318261  0.16448604 0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.08130125 0.87749851 1.01217865\n",
            " 1.01217865 1.01217865 1.01217865 1.01217865 0.79431373 0.73093484\n",
            " 0.98841157 0.96464448 0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.32689443 0.62794415 0.43384631 1.01217865\n",
            " 1.01217865 0.82204199 0.05357298 0.01       0.18033076 0.62002179\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.06545653 0.01396118 0.62002179 1.01217865 0.36650624\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.56060408 1.01217865 0.76262428 0.01792236 0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.05357298\n",
            " 0.76262428 1.01217865 0.28728263 0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.14864132 0.96464448\n",
            " 0.9012656  0.64378887 0.43780749 0.01396118 0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.33085561 0.9606833  1.01217865\n",
            " 1.01217865 0.48138047 0.10902951 0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.18825312 0.74677956 1.01217865 1.01217865\n",
            " 0.60417706 0.11695187 0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.07337889 0.37838978 1.00821747 1.01217865 0.75074074\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.99633393 1.01217865 0.99633393 0.26351555 0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.1922143  0.52495346 0.73489602 1.01217865\n",
            " 1.01217865 0.82996435 0.01792236 0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.16448604 0.5962547\n",
            " 0.91711032 1.01217865 1.01217865 1.01217865 1.00029511 0.73093484\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.10506833 0.46157457 0.88542088 1.01217865 1.01217865 1.01217865\n",
            " 1.01217865 0.80619727 0.31897207 0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.10110715 0.27143791 0.85373143 1.01217865\n",
            " 1.01217865 1.01217865 1.01217865 0.79431373 0.33085561 0.01792236\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.08130125 0.68736185\n",
            " 0.87749851 1.01217865 1.01217865 1.01217865 1.01217865 0.78243018\n",
            " 0.32689443 0.04565062 0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.22786492 0.69132303 0.90522678 1.01217865 1.01217865 1.01217865\n",
            " 1.01217865 0.97652803 0.536837   0.05357298 0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.54872054 1.01217865\n",
            " 1.01217865 1.01217865 0.84977025 0.54475936 0.53287582 0.07337889\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.01       0.01       0.01       0.01      ]\n",
            "\n",
            "scaled target for this image is:  [0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01]\n"
          ]
        }
      ]
    }
  ]
}